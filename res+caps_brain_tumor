{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1267593,"sourceType":"datasetVersion","datasetId":723383}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"!pip install -U albumentations","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:21.659499Z","iopub.execute_input":"2024-10-29T10:25:21.659906Z","iopub.status.idle":"2024-10-29T10:25:35.476318Z","shell.execute_reply.started":"2024-10-29T10:25:21.659866Z","shell.execute_reply":"2024-10-29T10:25:35.475234Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.4.15)\nCollecting albumentations\n  Downloading albumentations-1.4.20-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.26.4)\nRequirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.14.1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.2)\nRequirement already satisfied: pydantic>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (2.9.2)\nCollecting albucore==0.0.19 (from albumentations)\n  Downloading albucore-0.0.19-py3-none-any.whl.metadata (5.2 kB)\nRequirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.10.0.84)\nCollecting stringzilla>=3.10.4 (from albucore==0.0.19->albumentations)\n  Downloading stringzilla-3.10.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\nDownloading albumentations-1.4.20-py3-none-any.whl (225 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.8/225.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading albucore-0.0.19-py3-none-any.whl (11 kB)\nDownloading stringzilla-3.10.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (291 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.4/291.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: stringzilla, albucore, albumentations\n  Attempting uninstall: albucore\n    Found existing installation: albucore 0.0.16\n    Uninstalling albucore-0.0.16:\n      Successfully uninstalled albucore-0.0.16\n  Attempting uninstall: albumentations\n    Found existing installation: albumentations 1.4.15\n    Uninstalling albumentations-1.4.15:\n      Successfully uninstalled albumentations-1.4.15\nSuccessfully installed albucore-0.0.19 albumentations-1.4.20 stringzilla-3.10.5\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport h5py\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.utils import class_weight\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers, regularizers\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nimport random\nfrom tensorflow.keras.models import Model, load_model\nimport albumentations as A\nfrom collections import Counter\n\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:35.478338Z","iopub.execute_input":"2024-10-29T10:25:35.478646Z","iopub.status.idle":"2024-10-29T10:25:50.153499Z","shell.execute_reply.started":"2024-10-29T10:25:35.478610Z","shell.execute_reply":"2024-10-29T10:25:50.152538Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Global Parameters and Path","metadata":{}},{"cell_type":"code","source":"DATA_PATH = '/kaggle/input/brats2020-training-data/BraTS2020_training_data/content/data'\nNUM_CLASSES = 4\nBATCH_SIZE = 8\nEPOCHS = 25\nINPUT_HEIGHT = 128\nINPUT_WIDTH = 128\nINPUT_CHANNELS = 4\nTARGET_SIZE = (128, 128)\nIMG_HEIGHT, IMG_WIDTH = 128, 128","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:50.154813Z","iopub.execute_input":"2024-10-29T10:25:50.155368Z","iopub.status.idle":"2024-10-29T10:25:50.160701Z","shell.execute_reply.started":"2024-10-29T10:25:50.155332Z","shell.execute_reply":"2024-10-29T10:25:50.159672Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading and Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Load HDF5 Files","metadata":{}},{"cell_type":"code","source":"def load_hdf5_slice(filepath):\n    with h5py.File(filepath, 'r') as h5_file:\n        image_data = h5_file['image'][:]\n        mask_data = h5_file['mask'][:]\n    return image_data, mask_data","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:50.162694Z","iopub.execute_input":"2024-10-29T10:25:50.163085Z","iopub.status.idle":"2024-10-29T10:25:50.192305Z","shell.execute_reply.started":"2024-10-29T10:25:50.163042Z","shell.execute_reply":"2024-10-29T10:25:50.191420Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Normalize and Resize Images","metadata":{}},{"cell_type":"code","source":"def load_and_preprocess_slice(filepath, target_size=TARGET_SIZE):\n    with h5py.File(filepath, 'r') as h5_file:\n        image = h5_file['image'][:]  # Shape: (H, W, 4)\n        mask = h5_file['mask'][:]    # Shape: (H, W) or (H, W, D)\n    \n    # Normalize and resize image as before\n    image_min = np.min(image)\n    image_max = np.max(image)\n    if image_max > image_min:\n        image_normalized = (image - image_min) / (image_max - image_min)\n    else:\n        image_normalized = np.zeros_like(image)\n    image_resized = np.array([\n        cv2.resize(image_normalized[..., i], target_size)\n        for i in range(image.shape[-1])\n    ]).transpose(1, 2, 0)\n    \n    # Process mask\n    if mask.ndim == 3:\n        # Combine mask channels into a single channel\n        mask_combined = np.argmax(mask, axis=-1)\n        mask_resized = cv2.resize(mask_combined, target_size, interpolation=cv2.INTER_NEAREST)\n    else:\n        # Mask is already single-channel\n        mask_resized = cv2.resize(mask, target_size, interpolation=cv2.INTER_NEAREST)\n    \n    return image_resized.astype(np.float32), mask_resized.astype(np.int32)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:50.193396Z","iopub.execute_input":"2024-10-29T10:25:50.193674Z","iopub.status.idle":"2024-10-29T10:25:50.204967Z","shell.execute_reply.started":"2024-10-29T10:25:50.193642Z","shell.execute_reply":"2024-10-29T10:25:50.204058Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def check_for_invalid_values(image, mask, filepath):\n    if np.isnan(image).any() or np.isinf(image).any():\n        print(f\"Invalid values in image at {filepath}\")\n    if np.isnan(mask).any() or np.isinf(mask).any():\n        print(f\"Invalid values in mask at {filepath}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:50.206122Z","iopub.execute_input":"2024-10-29T10:25:50.206471Z","iopub.status.idle":"2024-10-29T10:25:50.220143Z","shell.execute_reply.started":"2024-10-29T10:25:50.206436Z","shell.execute_reply":"2024-10-29T10:25:50.219304Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess Slices","metadata":{}},{"cell_type":"code","source":"def preprocess_slice(image, mask, target_size=(INPUT_HEIGHT, INPUT_WIDTH)):\n    image_normalized = normalize_image(image)\n    image_resized = resize_image(image_normalized, target_size)\n    mask_resized = resize_mask(mask, target_size)\n    mask_resized = mask_resized.astype(np.int32)\n    return image_resized.astype(np.float32), mask_resized","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:50.221337Z","iopub.execute_input":"2024-10-29T10:25:50.221616Z","iopub.status.idle":"2024-10-29T10:25:50.230623Z","shell.execute_reply.started":"2024-10-29T10:25:50.221584Z","shell.execute_reply":"2024-10-29T10:25:50.229771Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_multi_hot_encoding(mask):\n    unique_classes = np.unique(mask)\n    encoding = np.zeros(NUM_CLASSES, dtype=np.int32)\n    encoding[unique_classes] = 1\n    return encoding","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:50.231602Z","iopub.execute_input":"2024-10-29T10:25:50.231884Z","iopub.status.idle":"2024-10-29T10:25:50.240582Z","shell.execute_reply.started":"2024-10-29T10:25:50.231853Z","shell.execute_reply":"2024-10-29T10:25:50.239662Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Split Dataset into Train, Validation, and Test Sets","metadata":{}},{"cell_type":"code","source":"all_files = [os.path.join(DATA_PATH, f) for f in os.listdir(DATA_PATH) if f.endswith('.h5')]\ntotal_files = len(all_files)\nprint(f\"Total number of slices: {total_files}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:50.241713Z","iopub.execute_input":"2024-10-29T10:25:50.242330Z","iopub.status.idle":"2024-10-29T10:25:51.084521Z","shell.execute_reply.started":"2024-10-29T10:25:50.242273Z","shell.execute_reply":"2024-10-29T10:25:51.083592Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Total number of slices: 57195\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Shuffle and Split Files","metadata":{}},{"cell_type":"code","source":"train_val_files, test_files = train_test_split(all_files, test_size=0.2, random_state=42)\ntrain_files, val_files = train_test_split(train_val_files, test_size=0.1, random_state=42) \n\nprint(f\"Training files: {len(train_files)}\")\nprint(f\"Validation files: {len(val_files)}\")\nprint(f\"Test files: {len(test_files)}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:51.087776Z","iopub.execute_input":"2024-10-29T10:25:51.088088Z","iopub.status.idle":"2024-10-29T10:25:51.126540Z","shell.execute_reply.started":"2024-10-29T10:25:51.088055Z","shell.execute_reply":"2024-10-29T10:25:51.125627Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Training files: 41180\nValidation files: 4576\nTest files: 11439\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Address Class Imbalance","metadata":{}},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"augmentation_pipeline = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.Rotate(limit=30, p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=30, p=0.5),\n    A.RandomBrightnessContrast(p=0.5),\n    A.GaussianBlur(p=0.2),\n    A.ElasticTransform(p=0.2),\n], additional_targets={'mask': 'mask'})","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:51.127617Z","iopub.execute_input":"2024-10-29T10:25:51.128005Z","iopub.status.idle":"2024-10-29T10:25:51.142956Z","shell.execute_reply.started":"2024-10-29T10:25:51.127962Z","shell.execute_reply":"2024-10-29T10:25:51.141622Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Custom Data Generator","metadata":{}},{"cell_type":"code","source":"class DataGenerator(Sequence):\n    def __init__(self, file_list, batch_size=BATCH_SIZE, target_size=(INPUT_HEIGHT, INPUT_WIDTH), augment=False, shuffle=True):\n        self.file_list = file_list\n        self.batch_size = batch_size\n        self.target_size = target_size\n        self.augment = augment\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(self.file_list))\n        self.on_epoch_end()\n                \n    def __len__(self):\n        return int(np.ceil(len(self.file_list) / self.batch_size))\n            \n    def __getitem__(self, index):\n        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        batch_files = [self.file_list[k] for k in batch_indexes]\n        X, y = self.__data_generation(batch_files)\n        return X, y\n            \n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def __data_generation(self, batch_files):\n        X = []\n        y = []\n        for file_path in batch_files:\n            image, mask = load_and_preprocess_slice(file_path)\n            if self.augment:\n                augmented = augmentation_pipeline(image=image, mask=mask)\n                image = augmented['image']\n                mask = augmented['mask']\n            X.append(image)\n            y.append(mask)\n        X = np.array(X)\n        y = np.array(y)\n        \n        # Convert masks to one-hot encoding\n        y = tf.keras.utils.to_categorical(y, num_classes=NUM_CLASSES)\n        \n        return X, y","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:51.144394Z","iopub.execute_input":"2024-10-29T10:25:51.144708Z","iopub.status.idle":"2024-10-29T10:25:51.177560Z","shell.execute_reply.started":"2024-10-29T10:25:51.144673Z","shell.execute_reply":"2024-10-29T10:25:51.176745Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# ResNet + CapsNet Model","metadata":{}},{"cell_type":"markdown","source":"## Capsule Layer","metadata":{}},{"cell_type":"code","source":"class CapsuleLayer(layers.Layer):\n    def __init__(self, num_capsules, capsule_dim, kernel_size, strides, padding, routings=3, **kwargs):\n        super(CapsuleLayer, self).__init__(**kwargs)\n        self.num_capsules = num_capsules\n        self.capsule_dim = capsule_dim\n        self.kernel_size = kernel_size\n        self.strides = strides\n        self.padding = padding\n        self.routings = routings\n\n    def build(self, input_shape):\n        self.input_capsule_dim = input_shape[-1]\n        self.W = self.add_weight(\n            shape=(self.kernel_size, self.kernel_size, self.input_capsule_dim, self.num_capsules * self.capsule_dim),\n            initializer='glorot_uniform',\n            trainable=True,\n            name='W'\n        )\n\n    def call(self, inputs):\n        u = tf.nn.conv2d(inputs, self.W, strides=[1, self.strides, self.strides, 1], padding=self.padding.upper())\n        batch_size, height, width, _ = tf.shape(u)[0], tf.shape(u)[1], tf.shape(u)[2], tf.shape(u)[3]\n        u = tf.reshape(u, [batch_size, height, width, self.num_capsules, self.capsule_dim])\n        for i in range(self.routings):\n            c = tf.nn.softmax(u, axis=-2)\n            s = tf.reduce_sum(c * u, axis=-2)\n            v = squash(s)\n            if i < self.routings - 1:\n                u += tf.reduce_sum(u * v[:, :, :, None, :], axis=-1, keepdims=True)\n        return v","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:51.178721Z","iopub.execute_input":"2024-10-29T10:25:51.179120Z","iopub.status.idle":"2024-10-29T10:25:51.191814Z","shell.execute_reply.started":"2024-10-29T10:25:51.179086Z","shell.execute_reply":"2024-10-29T10:25:51.190873Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def squash(vectors, axis=-1):\n    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis=axis, keepdims=True)\n    scale = s_squared_norm / (1 + s_squared_norm + tf.keras.backend.epsilon())\n    return scale * vectors / tf.sqrt(s_squared_norm + tf.keras.backend.epsilon())","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:51.192905Z","iopub.execute_input":"2024-10-29T10:25:51.193202Z","iopub.status.idle":"2024-10-29T10:25:51.205646Z","shell.execute_reply.started":"2024-10-29T10:25:51.193170Z","shell.execute_reply":"2024-10-29T10:25:51.204782Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class Length(layers.Layer):\n    def call(self, inputs, **kwargs):\n        return tf.sqrt(tf.reduce_sum(tf.square(inputs), axis=-1))","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:51.206623Z","iopub.execute_input":"2024-10-29T10:25:51.206919Z","iopub.status.idle":"2024-10-29T10:25:51.216855Z","shell.execute_reply.started":"2024-10-29T10:25:51.206887Z","shell.execute_reply":"2024-10-29T10:25:51.215923Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def dice_coefficient(y_true, y_pred, smooth=1e-7):\n    # Cast inputs to float32\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    \n    # Flatten the arrays\n    y_true_f = tf.reshape(y_true, [-1])\n    y_pred_f = tf.reshape(y_pred, [-1])\n    \n    # Calculate intersection and union\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coefficient(y_true, y_pred)\n\ndef combined_loss(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    \n    cce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n    \n    dice = dice_loss(y_true, y_pred)\n    \n    return cce + dice","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:51.217926Z","iopub.execute_input":"2024-10-29T10:25:51.218209Z","iopub.status.idle":"2024-10-29T10:25:51.227113Z","shell.execute_reply.started":"2024-10-29T10:25:51.218176Z","shell.execute_reply":"2024-10-29T10:25:51.226333Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def margin_loss(y_true, y_pred):\n    num_classes = tf.shape(y_pred)[-1]\n    y_true = tf.one_hot(tf.argmax(y_true, axis=1), depth=num_classes)\n    m_plus = 0.9\n    m_minus = 0.1\n    lambda_val = 0.5\n\n    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.0 - 1e-9)\n\n    L = y_true * tf.square(tf.maximum(0., m_plus - y_pred)) + \\\n        lambda_val * (1 - y_true) * tf.square(tf.maximum(0., y_pred - m_minus))\n\n    return tf.reduce_mean(tf.reduce_sum(L, axis=1))","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:51.228313Z","iopub.execute_input":"2024-10-29T10:25:51.228656Z","iopub.status.idle":"2024-10-29T10:25:51.239984Z","shell.execute_reply.started":"2024-10-29T10:25:51.228617Z","shell.execute_reply":"2024-10-29T10:25:51.239213Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Model Build","metadata":{}},{"cell_type":"code","source":"def create_hybrid_model():\n    inputs = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 4))\n    \n    # Map 4 channels to 3 channels\n    x = layers.Conv2D(3, (1, 1), padding='same', activation='relu')(inputs)\n    \n    # Preprocess inputs\n    x = layers.Lambda(tf.keras.applications.resnet50.preprocess_input)(x)\n    \n    # Base model\n    base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n    x = base_model(x)\n    \n    # Unfreeze last layers\n    for layer in base_model.layers[-10:]:\n        layer.trainable = True\n    \n    # Primary Capsule Layer\n    primary_caps = CapsuleLayer(\n        num_capsules=8,\n        capsule_dim=16,\n        kernel_size=3,\n        strides=1,\n        padding='same'\n    )(x)\n    \n    # Reshape and upsample\n    primary_caps_reshaped = layers.Reshape(\n        (primary_caps.shape[1], primary_caps.shape[2], -1)\n    )(primary_caps)\n    \n    # Upsample to match input size\n    x = layers.UpSampling2D(\n        size=(IMG_HEIGHT // primary_caps.shape[1], IMG_WIDTH // primary_caps.shape[2]), \n        interpolation='bilinear'\n    )(primary_caps_reshaped)\n    \n    # Final convolution layers to get the right number of channels\n    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n    \n    # Output layer with NUM_CLASSES channels and softmax activation\n    outputs = layers.Conv2D(NUM_CLASSES, (1, 1), padding='same', activation='softmax')(x)\n    \n    model = Model(inputs=inputs, outputs=outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:25:51.241063Z","iopub.execute_input":"2024-10-29T10:25:51.241381Z","iopub.status.idle":"2024-10-29T10:25:51.252906Z","shell.execute_reply.started":"2024-10-29T10:25:51.241349Z","shell.execute_reply":"2024-10-29T10:25:51.251976Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Compile Model","metadata":{}},{"cell_type":"code","source":"def create_and_compile_model():\n    model = create_hybrid_model()\n    optimizer = optimizers.Adam(learning_rate=1e-4)\n    model.compile(\n        optimizer=optimizer,\n        loss=combined_loss,\n        metrics=['accuracy', dice_coefficient]\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-29T11:02:21.718435Z","iopub.execute_input":"2024-10-29T11:02:21.719326Z","iopub.status.idle":"2024-10-29T11:02:21.724182Z","shell.execute_reply.started":"2024-10-29T11:02:21.719284Z","shell.execute_reply":"2024-10-29T11:02:21.723093Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def compute_class_weights_pixel_level(file_list, target_size=(INPUT_HEIGHT, INPUT_WIDTH)):\n    pixel_counts = np.zeros(NUM_CLASSES)\n    for file_path in file_list:\n        _, mask = load_and_preprocess_slice(file_path, target_size=target_size)\n        labels, counts = np.unique(mask, return_counts=True)\n        for label, count in zip(labels, counts):\n            pixel_counts[label] += count\n    total_pixels = np.sum(pixel_counts)\n    epsilon = 1e-6\n    class_weights = total_pixels / (NUM_CLASSES * (pixel_counts + epsilon))\n    \n    max_weight = 1000.0\n    class_weights = np.minimum(class_weights, max_weight)\n    \n    class_weights = class_weights / np.sum(class_weights) * NUM_CLASSES\n    \n    class_weights = dict(enumerate(class_weights))\n    return class_weights","metadata":{"execution":{"iopub.status.busy":"2024-10-29T11:02:24.770410Z","iopub.execute_input":"2024-10-29T11:02:24.771152Z","iopub.status.idle":"2024-10-29T11:02:24.778018Z","shell.execute_reply.started":"2024-10-29T11:02:24.771114Z","shell.execute_reply":"2024-10-29T11:02:24.776995Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"k = 5\nkf = KFold(n_splits=k, shuffle=True, random_state=42)\nepochs = EPOCHS\nbatch_size = BATCH_SIZE\ntrain_val_files = train_files + val_files  # 80% of data\n\nfor fold_no, (train_index, val_index) in enumerate(kf.split(train_val_files), 1):\n    print(f'\\nTraining for fold {fold_no} ...')\n    \n    # Create a new model instance for each fold\n    model = create_and_compile_model()\n    \n    train_files_fold = [train_val_files[i] for i in train_index]\n    val_files_fold = [train_val_files[i] for i in val_index]\n    \n    # Compute class weights for this fold\n    class_weights_fold = compute_class_weights_pixel_level(train_files_fold)\n    print(f\"Class weights for fold {fold_no}: {class_weights_fold}\")\n    \n    # Create data generators\n    train_generator = DataGenerator(train_files_fold, batch_size=batch_size, augment=True, shuffle=True)\n    val_generator = DataGenerator(val_files_fold, batch_size=batch_size, augment=False, shuffle=False)\n    \n    # Callbacks\n    checkpoint_filepath = f'best_model_fold_{fold_no}.keras'\n    callbacks = [\n        ModelCheckpoint(\n            filepath=checkpoint_filepath,\n            save_best_only=True,\n            monitor='val_loss',\n            mode='min'\n        ),\n        EarlyStopping(\n            monitor='val_loss',\n            patience=5,\n            restore_best_weights=True\n        ),\n        ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=3,\n            min_lr=1e-6\n        )\n    ]\n    \n    # Train the model\n    try:\n        history = model.fit(\n            train_generator,\n            validation_data=val_generator,\n            epochs=EPOCHS,\n            callbacks=callbacks,\n            verbose=1\n        )\n        \n        # Evaluate on validation data\n        val_loss, val_accuracy = model.evaluate(val_generator, verbose=0)\n        print(f'Fold {fold_no} Validation Loss: {val_loss}')\n        print(f'Fold {fold_no} Validation Accuracy: {val_accuracy}')\n        \n        # Save the model for this fold\n        model.save(f'model_fold_{fold_no}.keras')\n        \n    except Exception as e:\n        print(f\"Error in fold {fold_no}: {str(e)}\")\n        continue","metadata":{"execution":{"iopub.status.busy":"2024-10-29T11:02:28.557049Z","iopub.execute_input":"2024-10-29T11:02:28.557788Z","iopub.status.idle":"2024-10-29T22:16:52.355528Z","shell.execute_reply.started":"2024-10-29T11:02:28.557746Z","shell.execute_reply":"2024-10-29T22:16:52.354444Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"\nTraining for fold 1 ...\nClass weights for fold 1: {0: 0.0008757114312070468, 1: 0.13377557027709452, 2: 0.3929715691117816, 3: 3.472377149179917}\nEpoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1730200503.557049     108 service.cc:145] XLA service 0x7cef10006b30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1730200503.557113     108 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   1/4576\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m72:16:50\u001b[0m 57s/step - accuracy: 0.0014 - dice_coefficient: 0.2094 - loss: 2.3542","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1730200526.608965     108 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_9', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_7', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_5', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_11', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_13', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_12', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_23', 36 bytes spill stores, 56 bytes spill loads\nptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 4 bytes spill stores, 4 bytes spill loads\n\nI0000 00:00:1730200526.656919     108 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4012/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:31\u001b[0m 162ms/step - accuracy: 0.9755 - dice_coefficient: 0.9319 - loss: 0.1965","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1730201176.877413     105 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_9', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_7', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_5', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_11', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_13', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_12', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_23', 36 bytes spill stores, 56 bytes spill loads\nptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 4 bytes spill stores, 4 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m989s\u001b[0m 204ms/step - accuracy: 0.9772 - dice_coefficient: 0.9375 - loss: 0.1814 - val_accuracy: 0.9914 - val_dice_coefficient: 0.9911 - val_loss: 0.0744 - learning_rate: 1.0000e-04\nEpoch 2/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m875s\u001b[0m 191ms/step - accuracy: 0.9914 - dice_coefficient: 0.9888 - loss: 0.0370 - val_accuracy: 0.9914 - val_dice_coefficient: 0.9913 - val_loss: 0.1032 - learning_rate: 1.0000e-04\nEpoch 3/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m879s\u001b[0m 192ms/step - accuracy: 0.9915 - dice_coefficient: 0.9894 - loss: 0.0336 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9850 - val_loss: 0.0616 - learning_rate: 1.0000e-04\nEpoch 4/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m890s\u001b[0m 194ms/step - accuracy: 0.9917 - dice_coefficient: 0.9898 - loss: 0.0312 - val_accuracy: 0.9914 - val_dice_coefficient: 0.9898 - val_loss: 0.0668 - learning_rate: 1.0000e-04\nEpoch 5/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m904s\u001b[0m 197ms/step - accuracy: 0.9920 - dice_coefficient: 0.9901 - loss: 0.0301 - val_accuracy: 0.9914 - val_dice_coefficient: 0.9904 - val_loss: 0.0641 - learning_rate: 1.0000e-04\nEpoch 6/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m887s\u001b[0m 194ms/step - accuracy: 0.9921 - dice_coefficient: 0.9904 - loss: 0.0289 - val_accuracy: 0.9612 - val_dice_coefficient: 0.9348 - val_loss: 0.1948 - learning_rate: 1.0000e-04\nEpoch 7/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m872s\u001b[0m 190ms/step - accuracy: 0.9923 - dice_coefficient: 0.9906 - loss: 0.0278 - val_accuracy: 0.9191 - val_dice_coefficient: 0.9237 - val_loss: 0.2538 - learning_rate: 5.0000e-05\nEpoch 8/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m885s\u001b[0m 193ms/step - accuracy: 0.9927 - dice_coefficient: 0.9910 - loss: 0.0266 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9869 - val_loss: 0.0979 - learning_rate: 5.0000e-05\nError in fold 1: too many values to unpack (expected 2)\n\nTraining for fold 2 ...\nClass weights for fold 2: {0: 0.0008755702374575218, 1: 0.1342609364763253, 2: 0.39296012637270933, 3: 3.4719033669135078}\nEpoch 1/25\n\u001b[1m 419/4576\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:06\u001b[0m 204ms/step - accuracy: 0.9914 - dice_coefficient: 0.8252 - loss: 0.4446","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1730208597.093978     106 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_9', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_7', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_5', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_11', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_13', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_12', 4 bytes spill stores, 12 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_23', 36 bytes spill stores, 56 bytes spill loads\nptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 4 bytes spill stores, 4 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m981s\u001b[0m 203ms/step - accuracy: 0.9912 - dice_coefficient: 0.9616 - loss: 0.1188 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9857 - val_loss: 0.0682 - learning_rate: 1.0000e-04\nEpoch 2/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m930s\u001b[0m 203ms/step - accuracy: 0.9913 - dice_coefficient: 0.9873 - loss: 0.0513 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9845 - val_loss: 0.0641 - learning_rate: 1.0000e-04\nEpoch 3/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m934s\u001b[0m 204ms/step - accuracy: 0.9912 - dice_coefficient: 0.9878 - loss: 0.0448 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9882 - val_loss: 0.0514 - learning_rate: 1.0000e-04\nEpoch 4/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m909s\u001b[0m 198ms/step - accuracy: 0.9914 - dice_coefficient: 0.9882 - loss: 0.0433 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9899 - val_loss: 0.0707 - learning_rate: 1.0000e-04\nEpoch 5/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m924s\u001b[0m 202ms/step - accuracy: 0.9913 - dice_coefficient: 0.9885 - loss: 0.0392 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9903 - val_loss: 0.1284 - learning_rate: 1.0000e-04\nEpoch 6/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m934s\u001b[0m 204ms/step - accuracy: 0.9913 - dice_coefficient: 0.9888 - loss: 0.0374 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9911 - val_loss: 0.0897 - learning_rate: 1.0000e-04\nEpoch 7/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m919s\u001b[0m 201ms/step - accuracy: 0.9914 - dice_coefficient: 0.9892 - loss: 0.0348 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9911 - val_loss: 0.1189 - learning_rate: 5.0000e-05\nEpoch 8/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m906s\u001b[0m 198ms/step - accuracy: 0.9917 - dice_coefficient: 0.9896 - loss: 0.0331 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9907 - val_loss: 0.0938 - learning_rate: 5.0000e-05\nError in fold 2: too many values to unpack (expected 2)\n\nTraining for fold 3 ...\nClass weights for fold 3: {0: 0.0008754990249678236, 1: 0.13389459894418232, 2: 0.39365434356606394, 3: 3.4715755584647856}\nEpoch 1/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1003s\u001b[0m 208ms/step - accuracy: 0.9894 - dice_coefficient: 0.9519 - loss: 0.1406 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9912 - val_loss: 0.0778 - learning_rate: 1.0000e-04\nEpoch 2/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m929s\u001b[0m 203ms/step - accuracy: 0.9914 - dice_coefficient: 0.9891 - loss: 0.0347 - val_accuracy: 0.9916 - val_dice_coefficient: 0.9867 - val_loss: 0.0351 - learning_rate: 1.0000e-04\nEpoch 3/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m937s\u001b[0m 204ms/step - accuracy: 0.9918 - dice_coefficient: 0.9899 - loss: 0.0309 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9905 - val_loss: 0.0512 - learning_rate: 1.0000e-04\nEpoch 4/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m923s\u001b[0m 202ms/step - accuracy: 0.9920 - dice_coefficient: 0.9902 - loss: 0.0298 - val_accuracy: 0.9915 - val_dice_coefficient: 0.9892 - val_loss: 0.0377 - learning_rate: 1.0000e-04\nEpoch 5/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m937s\u001b[0m 205ms/step - accuracy: 0.9921 - dice_coefficient: 0.9903 - loss: 0.0289 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9902 - val_loss: 0.0447 - learning_rate: 1.0000e-04\nEpoch 6/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m933s\u001b[0m 204ms/step - accuracy: 0.9925 - dice_coefficient: 0.9908 - loss: 0.0272 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9911 - val_loss: 0.2741 - learning_rate: 5.0000e-05\nEpoch 7/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m915s\u001b[0m 200ms/step - accuracy: 0.9929 - dice_coefficient: 0.9911 - loss: 0.0263 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9908 - val_loss: 0.0809 - learning_rate: 5.0000e-05\nError in fold 3: too many values to unpack (expected 2)\n\nTraining for fold 4 ...\nClass weights for fold 4: {0: 0.000875343374407322, 1: 0.13395514582527365, 2: 0.39418531228003556, 3: 3.4709841985202834}\nEpoch 1/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1009s\u001b[0m 209ms/step - accuracy: 0.9912 - dice_coefficient: 0.9476 - loss: 0.1556 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9890 - val_loss: 0.0454 - learning_rate: 1.0000e-04\nEpoch 2/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m929s\u001b[0m 203ms/step - accuracy: 0.9914 - dice_coefficient: 0.9890 - loss: 0.0355 - val_accuracy: 0.9910 - val_dice_coefficient: 0.9839 - val_loss: 0.0462 - learning_rate: 1.0000e-04\nEpoch 3/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m916s\u001b[0m 200ms/step - accuracy: 0.9916 - dice_coefficient: 0.9896 - loss: 0.0321 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9913 - val_loss: 0.1196 - learning_rate: 1.0000e-04\nEpoch 4/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m918s\u001b[0m 200ms/step - accuracy: 0.9919 - dice_coefficient: 0.9901 - loss: 0.0297 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9912 - val_loss: 0.0875 - learning_rate: 1.0000e-04\nEpoch 5/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m927s\u001b[0m 202ms/step - accuracy: 0.9921 - dice_coefficient: 0.9904 - loss: 0.0283 - val_accuracy: 0.9913 - val_dice_coefficient: 0.9912 - val_loss: 0.0601 - learning_rate: 5.0000e-05\nEpoch 6/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m926s\u001b[0m 202ms/step - accuracy: 0.9923 - dice_coefficient: 0.9907 - loss: 0.0273 - val_accuracy: 0.9914 - val_dice_coefficient: 0.9903 - val_loss: 0.0458 - learning_rate: 5.0000e-05\nError in fold 4: too many values to unpack (expected 2)\n\nTraining for fold 5 ...\nClass weights for fold 5: {0: 0.0008758181213725943, 1: 0.13373283942667344, 2: 0.3926091096909395, 3: 3.472782232761014}\nEpoch 1/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m986s\u001b[0m 204ms/step - accuracy: 0.9829 - dice_coefficient: 0.9485 - loss: 0.1528 - val_accuracy: 0.9914 - val_dice_coefficient: 0.9906 - val_loss: 0.0514 - learning_rate: 1.0000e-04\nEpoch 2/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m898s\u001b[0m 196ms/step - accuracy: 0.9912 - dice_coefficient: 0.9887 - loss: 0.0367 - val_accuracy: 0.9914 - val_dice_coefficient: 0.9910 - val_loss: 0.0588 - learning_rate: 1.0000e-04\nEpoch 3/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m943s\u001b[0m 206ms/step - accuracy: 0.9916 - dice_coefficient: 0.9894 - loss: 0.0331 - val_accuracy: 0.9914 - val_dice_coefficient: 0.9913 - val_loss: 0.0848 - learning_rate: 1.0000e-04\nEpoch 4/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m971s\u001b[0m 212ms/step - accuracy: 0.9919 - dice_coefficient: 0.9900 - loss: 0.0306 - val_accuracy: 0.9914 - val_dice_coefficient: 0.9914 - val_loss: 0.1347 - learning_rate: 1.0000e-04\nEpoch 5/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1006s\u001b[0m 220ms/step - accuracy: 0.9925 - dice_coefficient: 0.9907 - loss: 0.0281 - val_accuracy: 0.9924 - val_dice_coefficient: 0.9916 - val_loss: 0.0297 - learning_rate: 5.0000e-05\nEpoch 6/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m961s\u001b[0m 210ms/step - accuracy: 0.9927 - dice_coefficient: 0.9908 - loss: 0.0274 - val_accuracy: 0.9914 - val_dice_coefficient: 0.9911 - val_loss: 0.0512 - learning_rate: 5.0000e-05\nEpoch 7/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m936s\u001b[0m 204ms/step - accuracy: 0.9929 - dice_coefficient: 0.9911 - loss: 0.0266 - val_accuracy: 0.9920 - val_dice_coefficient: 0.9896 - val_loss: 0.0390 - learning_rate: 5.0000e-05\nEpoch 8/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m949s\u001b[0m 207ms/step - accuracy: 0.9932 - dice_coefficient: 0.9914 - loss: 0.0256 - val_accuracy: 0.9914 - val_dice_coefficient: 0.9913 - val_loss: 0.1177 - learning_rate: 5.0000e-05\nEpoch 9/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m941s\u001b[0m 205ms/step - accuracy: 0.9935 - dice_coefficient: 0.9918 - loss: 0.0243 - val_accuracy: 0.9914 - val_dice_coefficient: 0.9914 - val_loss: 0.1915 - learning_rate: 2.5000e-05\nEpoch 10/25\n\u001b[1m4576/4576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m935s\u001b[0m 204ms/step - accuracy: 0.9936 - dice_coefficient: 0.9920 - loss: 0.0238 - val_accuracy: 0.9918 - val_dice_coefficient: 0.9914 - val_loss: 0.0509 - learning_rate: 2.5000e-05\nError in fold 5: too many values to unpack (expected 2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Evaluate the Model on the Test Set","metadata":{}},{"cell_type":"code","source":"test_generator = DataGenerator(test_files, batch_size=1, augment=False, shuffle=False)\n\ntest_dice = model.evaluate(test_generator, verbose=1)\nprint(f'Test Dice Coefficient: {test_dice[1]}')\n\ny_preds = []\ny_trues = []\nfor i in range(len(test_generator)):\n    X, y_true = test_generator[i]\n    y_pred = model.predict(X)\n    y_preds.append(y_pred)\n    y_trues.append(y_true)\n\ny_preds_flat = np.concatenate([y_pred.flatten() for y_pred in y_preds])\ny_trues_flat = np.concatenate([y_true.flatten() for y_true in y_trues])\n\ny_preds_flat = (y_preds_flat > 0.5).astype(np.uint8)\n\nprecision = precision_score(y_trues_flat, y_preds_flat, zero_division=0)\nrecall = recall_score(y_trues_flat, y_preds_flat, zero_division=0)\nf1 = f1_score(y_trues_flat, y_preds_flat, zero_division=0)\n\nprint(f'Precision: {precision}, Recall: {recall}, F1-Score: {f1}')","metadata":{"execution":{"iopub.status.busy":"2024-10-29T22:22:13.424052Z","iopub.execute_input":"2024-10-29T22:22:13.424877Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\u001b[1m 6070/11439\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 24ms/step - accuracy: 0.9922 - dice_coefficient: 0.9915 - loss: 0.0303","output_type":"stream"}]}]}